# KNN k-近邻算法
*****

*****
## KNN 概述
k-近邻（KNN，K-NearestNeighbor）算法是一种基本分类与回归方法，现在这里只讨论分类问题中的k-近邻算法  

KNN算法用一句话总结就是：近朱者赤近墨者黑  

k-近邻算法的输入为实例的特征向量，对应于特征空间的点，输出为实例的类别，可以取多个类别，即多分类。k近邻算法假设给定一个训练数据集，其中的实例类别已定。分类时对新的实例根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，k-近邻算法不具有显式的学习过程。

k-近邻算法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。k值得选择、距离度量以及分类决策规则是k-近邻算法的三个基本要素。

## KNN 场景
这里用一个十分老套的例子进行说明：  
电影可以按照题材分类，如何让机器区分**动作片** 和 **爱情片** 呢？
1. 动作片：打斗次数多
2. 爱情片：亲吻次数多
基于电影中的亲吻、打斗出现的次数，使用k-近邻算法构造程序，就可以自动划分电影的题材类型

|电影名称|打斗次数|亲吻次数|电影题材|
|---|----|-----|-----|
|A|3|104|爱情片|
|B|2|100|爱情片|
|C|1|81|爱情片|
|D|101|10|动作片|
|E|99|5|动作片|
|F|98|2|动作片|
|G|32|85|?|

#### 计算未知电影到已知电影之间的距离
我们将上述的电影按作打斗次数和亲吻次数在直角坐标系中标出，如果G电影是爱情电影，那么他在坐标系上的点更接近爱情片所在的范围，如果G电影是动作片，他在坐标系上的点更接近爱情片所在的范围，因此，我们计算所有电影和未知电影的距离，按照距离递增排序，结果如下  

|电影名称|与未知电影的位置|
|-------|---------------|
|C|31.26|
|B|33.54|
|A|34.67|
|D|101.91|
|E|104.35|
|F|106.04|

当我们设定 K = 3 是，前三个最近的点 分别为 C,B,A ,三个点有3个爱情片，0个动作片，所以我们可以认为 G 电影可能为 爱情片

## KNN 原理
### 工作原理
1. 假设有一个带有标签的样本数据集（训练样本集），其中包含每条数据和所属分类的对应关系
2. 输入没有标签的新数据，将新数据的每个特征与样本集中数据对应的特征进行比较
  i. 计算新数据和样本数据集中每条数据的距离
  ii. 对求得的所有距离进行递增排序
  iii. 取前k个样本数据对应的分类标签
3. 将 k 个数据中出现次数最多的标签作为新数据的分类
### 通俗理解
给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的 k 个实例，这 k 个实例的多数属于某个类，就把该输入实例分为这个类。
### KNN 算法特点
**优点**：精度高、对异常值不敏感、无数据输入假定
**缺点**：计算复杂度高、空间复杂度高
**适用数据范围**：数值型和标称型

## KNN项目案例
### 项目一：优化约会对象的配对效果
#### 项目概述
渣女小倩使用约会网站寻找约会对象，经过一段时间之后，她归纳总结了曾经交往的三种类型的人
* 不喜欢的那屌丝
* 魅力一般的普通人
* 极具魅力的高富帅
她希望
1. 工作日与魅力一般的人普通人约会
2. 周末与极具魅力的高富帅约会
3. 不喜欢的男屌丝则直接排除掉

现在她收集了一些约会网站曾经记录的数据信息，希望通过这些数据对将来的约会对象进行归类
